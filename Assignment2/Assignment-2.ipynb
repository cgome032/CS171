{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0: Getting real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "dataUrl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
    "rawData = urllib.request.urlopen(dataUrl)\n",
    "dataHeaders = ['code_number', 'clump_thickness', 'cell_size', 'cell_shape', 'marginal_adhesion', 'single_cell_size', 'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses', 'class']\n",
    "\n",
    "data = np.genfromtxt(rawData, delimiter=',', dtype=int, missing_values={6:'?'}, filling_values={6:999})\n",
    "#np.random.shuffle(data)\n",
    "\n",
    "split = math.ceil(len(data) * .80)\n",
    "\n",
    "trainingData, testData = data[:split], data[split:]\n",
    "y_train = [i[10] for i in trainingData]\n",
    "\n",
    "# Need to keep this around to check if accurate\n",
    "x_train = [i[10] for i in testData] \n",
    "\n",
    "trainingData = np.delete(trainingData, 10, axis=1)\n",
    "testData = np.delete(testData, 10, axis=1)\n",
    "\n",
    "trainingData = np.delete(trainingData, 0, axis=1)\n",
    "testData = np.delete(testData, 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: k-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.28057553956835\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function to find distance between two vectors\n",
    "\"\"\"\n",
    "def LP_distance(x,y,p):\n",
    "    totalDistance = 0\n",
    "    for i,j in zip(x,y):\n",
    "        newDistance = (abs(i-j)**p)\n",
    "        totalDistance += newDistance\n",
    "    return (totalDistance**(1/p))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function gets k neighbors for one tuple\n",
    "\"\"\"\n",
    "def get_k_neighbors(trainingData, testTuple, y_train, k, p):\n",
    "    allDistances = []\n",
    "    trainCnt = 0\n",
    "    for dataEntry in trainingData:\n",
    "        newDistance = LP_distance(dataEntry, testTuple, p)\n",
    "        allDistances.append((newDistance, y_train[trainCnt]))\n",
    "        trainCnt += 1\n",
    "    allDistances = sorted(allDistances, key=itemgetter(0))\n",
    "    \n",
    "    kDistances = [val[1] for val in allDistances[:k]]\n",
    "    return kDistances\n",
    "    \n",
    "\n",
    "def knn_classifier(x_test, x_train, y_train, k, p):\n",
    "    y_pred = []\n",
    "    \n",
    "    for testValue in x_test:\n",
    "        \n",
    "        neighbors = get_k_neighbors(x_train, testValue, y_train, k, p)\n",
    "        countClass = list(Counter(neighbors).keys())\n",
    "        y_pred.append(countClass[0])\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "result = knn_classifier(testData, trainingData, y_train, 1, 2)\n",
    "\n",
    "sameCount = 0\n",
    "for i,j in zip(x_train, result):\n",
    "    if i == j:\n",
    "        sameCount += 1\n",
    "\n",
    "print(sameCount/len(x_train) * 100)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting up the data into 10 sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "\n",
    "\n",
    "splitData = data[:]\n",
    "\n",
    "#splitData = [data[i:i + split_ten] for i in range(0, len(data), split_ten)]\n",
    "\n",
    "count = 0\n",
    "y_train = [i[10] for i in splitData]\n",
    "splitData = np.delete(splitData, 10, axis=1)\n",
    "splitData= np.delete(splitData, 0, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using knn classifier to get results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "\n",
    "splitData: Contains test data and training data split into 10 sections\n",
    "y_train: Contains training data classes\n",
    "\n",
    "Output:\n",
    "y_splitPred: Contains test data classes\n",
    "\n",
    "\"\"\"\n",
    "def tenCrossValidation(data, y_train, k, p):\n",
    "    y_predList = []\n",
    "    split_ten = math.ceil(len(data)/10)\n",
    "    currentPos = 0\n",
    "\n",
    "    for current in range(10):\n",
    "        # Getting the current slice of data to test on\n",
    "        testData = splitData[currentPos:currentPos+split_ten]\n",
    "        y_testData = y_train[currentPos:currentPos+split_ten]\n",
    "\n",
    "        # Getting the current data to be training from\n",
    "        #trainingData = [e for e in splitData if e not in testData]\n",
    "        #y_trainCopy = [d for d in y_train if d not in y_testData]\n",
    "\n",
    "        trainingData = []\n",
    "        y_trainCopy = []\n",
    "\n",
    "        if currentPos == 0:\n",
    "            trainingData = splitData[currentPos+split_ten:]\n",
    "            y_trainCopy = y_train[currentPos+split_ten:]\n",
    "\n",
    "        elif currentPos+split_ten >= (len(splitData)-1):\n",
    "            trainingData = splitData[0:currentPos]\n",
    "            y_trainCopy = y_train[0:currentPos]\n",
    "\n",
    "\n",
    "        else:\n",
    "            a_train = splitData[0:currentPos]\n",
    "            b_train = splitData[currentPos+split_ten:]\n",
    "\n",
    "            trainingData = np.concatenate((a_train, b_train), axis=0)\n",
    "\n",
    "            a_y = y_train[0:currentPos]\n",
    "            b_y = y_train[currentPos+split_ten:]\n",
    "\n",
    "            y_trainCopy = np.concatenate((a_y, b_y), axis=0)\n",
    "\n",
    "\n",
    "        y_pred = knn_classifier(testData, trainingData, y_trainCopy, k, p)\n",
    "        y_predList.append(y_pred)\n",
    "\n",
    "        currentPos += split_ten\n",
    "    return y_predList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSensitivity(y_pred, y_train):\n",
    "    tp_count = 0\n",
    "    fn_count = 0\n",
    "    for i,j in zip(y_pred, y_train):\n",
    "        if i == 4 and j == 4:\n",
    "            tp_count += 1\n",
    "        if i == 2 and j == 4:\n",
    "            fn_count += 1\n",
    "        \n",
    "    sensitivity = tp_count/(tp_count + fn_count) * 100\n",
    "    return sensitivity\n",
    "\n",
    "def testSpecificity(y_pred, y_train):\n",
    "    tn_count = 0\n",
    "    fp_count = 0\n",
    "    for i,j in zip(y_pred, y_train):\n",
    "        if i == 2 and j == 2:\n",
    "            tn_count += 1\n",
    "        if i == 4 and j == 2:\n",
    "            fp_count += 1\n",
    "    specificity = tn_count/(tn_count + fp_count) * 100\n",
    "    return specificity\n",
    "\n",
    "def testAccuracy(y_pred, y_train):\n",
    "    sameCount = 0\n",
    "    for i,j in zip(y_pred, y_train):\n",
    "        if i == j:\n",
    "            sameCount += 1\n",
    "    accuracy = (sameCount/len(y_train)) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.13733905579399\n",
      "Sensitivity: 93.7759336099585\n",
      "Specificity: 97.37991266375546\n"
     ]
    }
   ],
   "source": [
    "# tenCrossValidation will return a list of lists containing the\n",
    "# prediction for our knn algorithm\n",
    "\n",
    "y_predList = tenCrossValidation(data,y_train, 10,2)\n",
    "\n",
    "# Need to flatten list of lists to a single list to allow for \n",
    "# easier testing\n",
    "\n",
    "flat_y_predList = [item for sublist in y_predList for item in sublist]\n",
    "\n",
    "print(\"Accuracy:\", testAccuracy(flat_y_predList, y_train))\n",
    "print(\"Sensitivity:\", testSensitivity(flat_y_predList, y_train))\n",
    "print(\"Specificity:\", testSpecificity(flat_y_predList, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "1. https://stackoverflow.com/questions/10695139/sort-a-list-of-tuples-by-2nd-item-integer-value\n",
    "2. https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.delete.html\n",
    "3. https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
